\documentclass[paper=a4, fontsize=11pt]{scrartcl} % A4 paper and 11pt font size

\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage{fourier} % Use the Adobe Utopia font for the document - comment this line to return to the LaTeX default
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages

\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template
\usepackage{minted}
\usepackage{sectsty} % Allows customizing section commands
\allsectionsfont{\scshape} % Make all sections centered, the default font and small caps

\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
% \setlength{\headheight}{13.6pt} % Customize the height of the header

\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text

\newtheorem{thm}{Theorem}
\newcounter{claimcounter}
\numberwithin{claimcounter}{section}
\newenvironment{claim}{\stepcounter{claimcounter}{\textbf{Claim \theclaimcounter:}}}{}

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{	
\normalfont \normalsize 
\textsc{University of California San Diego} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge CSE 202: Design and Analysis of Algorithms Homework 1 \\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\usepackage[linesnumbered,lined,commentsnumbered]{algorithm2e}
\author{Sai Bi} % Your name

\date{\normalsize\today} % Today's date or a custom date

\begin{document}

\maketitle % Print the title

\section{Next greater element}

\subsection*{Algorithm description:}
The next greater element can be computed with a single scan of the array from
left to right. Let $A$ be the array, and $ST$ be a stack. We use $NGE$ to store
the NGE of each element.

For an element $i$, we do the following:
\begin{enumerate}
  \item \label{list:a} If $ST$ is empty, push a pair $i$ to $ST$.
  \item If $ST$ is not empty, let $k$ be the top element of $ST$.
    \begin{enumerate}
      \item If $A[k] \geq A[i]$, then push $i$ to $ST$.
      \item If $A[k] < A[i]$, then $NGE[k] = A[i]$. Pop top element from the
        stack. Go to Step~\ref{list:a}.
    \end{enumerate}
\end{enumerate}
After the scan of the array finished, if there are still elements in the stack
$ST$, pop them from the stack mark their NGE as \textit{null}.

\subsection*{Pseudocode}
\begin{minted}[linenos=true, mathescape, frame=lines, framesep=2mm]{cpp}
  Input: A[1...N]
  Output: B[1...N]

  ST = stack();
  for (i = 1; i <= N; i++) {
    while (!ST.empty()) {
      k = ST.top();
      if (A[k] >= A[i]) {
        break;
      } else {
        B[k] = A[i];
        ST.pop();
      }
    }
    ST.push_back(i);
  } 

  while (!ST.empty()) {
    k = ST.top();
    B[k] = null; 
    ST.pop();
  }

  print B;
  return B;
\end{minted}

\subsection*{Proof of correctness}
\begin{claim}
Each element will be pushed to the stack exactly once, and will also be 
popped out from stack exactly once.
\end{claim}

\textbf{Proof:}
From Line $15$, we know that each element $A[i]$ will be pushed to 
stack exactly once at $i-th$ iteration. Also some elements are popped at 
Line $12$, and for the remaining elements in stack, they are popped out 
at Line $21$. 

Therefore the claim holds.

\begin{claim}\label{claim:prob1}
For $1 \leq i \leq n $, after $i-th$ iteration, the values in $A$ corresponding
to the indices stored in stack are in descending order. 
\end{claim}

\textbf{Proof:}
After the first iteration, that is $i=1$, there is only one element in the
stack, and obviously the claim holds.

Assume that the claim holds after $i = k$ iterations. When $i = k+1$, 
\begin{enumerate}
  \item if $A[i] <= A[ST.top()]$, $i$ will be pushed to the stack and the stack remains
    in descending order of values.
  \item if $A[i] > A[ST.top()]$, then top element will be popped, and this step will be
    repeated until $A[i] <= A[ST.top()]$ or stack is empty. Then $i$ is pushed to the stack 
    and the stack remains  in descending order of values for both cases.
\end{enumerate}
Therefore, the claim holds.

\begin{claim}\label{cl:2}
  For $1 \leq i \leq n$,
  if stack is not empty, let $k = ST.top()$,
  if $A[i] > A[k]$, then $A[i]$ must the NGE
  of A[k].
\end{claim}

\textbf{Proof:}
Otherwise, it means that there must exist an element $k < j < i$ such that
$A[j] > A[k]$. In this case, at $j-th$ iteration, based on
Claim~\ref{claim:prob1}, we know that the values corresponding to the indices
stored in stack are in descending order, then $A[St.top()] \leq A[k] < A[j]$,
then we know that top elements will be popped from stack until stack is empty
or $A[st.top] >= A[j]$, which means that $k$ will be popped out, and it will 
not be in stack at iteration $i$, which forms a contradiction. Therefore,
the claim holds.

\begin{claim}
  If $k$ remains in stack after all iterations, it doesn't has a NGE. 
\end{claim}

\textbf{Proof:}
Assume $A[k]$ has an NGE $A[j]$, where $j > k$. Similarly at iteration $j$,
$A[ST.top()] <= A[k] < A[j]$, and then top elements will be popped 
out from stack until stack is empty or $A[ST.top] \geq A[j]$. Then we know that
$k$ will be popped out, which contradicts to the preconditions.

Therefore, the claim holds.

\vspace{0.5cm}
Given above claims, the correctness of the algorithm can be proved.

\subsection*{Time complexity}
Since each element is pushed and poped from stack once, the time complexity of
the algorithms is $O(n)$.


\section{Sorted matrix search}
\subsection*{Algorithm description:}
Let the target element be $T$.
Start from the top right corner of the matrix, if current element is smaller
than $T$, we go to the next element in the same column. If current element is 
larger than $T$, we go to the previous element in the same row. If equal, return
current position. Repeat this until we find the target or we have exceeded the
boundary of the matrix.

\subsection*{Pseudocode}
\begin{minted}[frame=lines, framesep=2mm]{cpp}
  Input: m*n matrix M, target element T
  Output: (x, y) // position of T

  y = 1;
  x = n;
  while (true) {
    if (x < 0 || y < 0 || x > n || y > m) {
      return null; // target not found.
    }

    if (M[y][x] > T) {
      x--;
    } else if (M[y][x] < T) {
      y++;
    } else {
      return (x, y);
    }
  }
\end{minted}

\subsection*{Proof of correctness}
\begin{claim} \label{cl:3}
Every time we arrive at a position $(x, y)$, $T$ can only be found in region
$[y...m, 1...x]$.
\end{claim}
\textbf{Proof:}
When $x=n,y=1$, obviously $T$ can only be found $[1...m, 1...n]$. The claim
holds.

Suppose it holds for $x \geq j, y \leq i$, that is, $T$ can only be found 
at $[i...m, 1...j]$. 
\begin{enumerate}
\item If $M[i][j] > T$, then $M[i...m][j] > T$, so $T$ can only be
found in region $[i...m, 1...j-1]$, and we will arrive at $(i, j-1)$. So the
claim also holds for $x \geq j-1, y \leq i$. 
    
\item If $M[i][j] < T$, then 
$M[i][1...j] < T$, so $T$ can only be found in region $[i+1...m, 1...j]$, and we
will arrive at $(i+1, j)$, so the claim holds for $x \geq j, y \leq i+1$. 

\item If $M[i][j] = T$, we have found the target $T$, no position update will be
  made.
\end{enumerate}
Therefore, the claim holds.

\begin{claim}
  If we arrive at position $(x,y)$ and $M[y][x] > T$, $T$ can only be found in 
  the region $[y...m, 1...x-1]$.
\end{claim}

\textbf{Proof:}
Given Claim~\ref{cl:3}, we know that $T$ can only be found in region $[y...m,
1...x]$. Since $M[y][x] > T$, we have $M[y...m][x] > T$, so $T$ can only 
be found in region $[y...m, 1...x-1]$.

\begin{claim}
  If we arrive at position $(x,y)$ and $M[y][x] < T$, $T$ can only be found in 
  the region $[y+1...m, 1...x]$.
\end{claim}

\textbf{Proof:}
Given Claim~\ref{cl:3}, we know that $T$ can only be found in region $[y...m,
1...x]$. Since $M[y][x] < T$, we have $M[y][1...x] < T$, so $T$ can only 
be found in region $[y+1...m, 1...x]$.

\vspace{0.5cm}
Given above claims, we conclude that every time we arrive at a position $(x,y)$,
\begin{enumerate}
  \item If $M[y][x] = T$, target is found and returned.
  \item If $M[y][x] > T$, we just need to search the region $[y\dots m, 1\dots
    x-1]$. That is we go to position $(y, x-1)$.
  \item If $M[y][x] < T$, we just need to search the region $[y+ 1\dots m, 1\dots
    x]$. That is we go to position $(y+1, x)$.
\end{enumerate}
If $T$ is not found after we exceed matrix boundary, then $T$ doesn't exist in 
matrix.

\subsection*{Time complexity}
For every iteration, the algorithm either goes down one step or goes left 
one step. It terminated when target is found or matrix boundary is
exceeded. And It takes at most $n+m$ steps to exceed matrix boundary. 
Therefore, the time complexity is $O(n+m)$. 



\section{Maximum overlap of two intervals}
\subsection*{Algorithm description:}
Sort all the intervals in ascending order of starting point. Initial $t$ with
the endpoint of the first interval, that is $t = b_1$. Initial $d = 0$. 
Scan the rest of intervals from left to
right, and for current interval $[a_i, b_i], i = 2...n$, we update the maximum overlapping
as $d = \max(\min(t,b_i) - a_i, d)$, and update $t = \max(b_i, t)$. Return $d$ as the maximum overlap. 

\subsection*{Pseudocode}
\begin{minted}[frame=lines, framesep=2mm]{cpp}
  Input: [a_i, b_i], i = 1...n
  Output: maximum overlapping d

  // sort all intervals in ascending order of starting point.
  [a_i, b_i] = sortIntervals([a_i, b_i]);
  d = 0;
  t = b_1;
  for (i = 2; i <= n; i++) {
    curr_d = min(t, b_i) - a_i;
    d = max(curr_d, d);
    t = max(b_i, t);
  }
  return d;
\end{minted}

\subsection*{Proof of correctness}
\begin{claim}
  For the sorted intervals, the maximum overlapping of $[a_i, b_i], i > 2$ with
  previous intervals is $\max(\min(t, b_i) - a_i, 0)$, where $t$ is the largest
  endpoint of previous intervals.
\end{claim}

\textbf{Proof:}
Since all the intervals are sorted in ascending order of starting point, so the
starting point of the overlapping must be $a_i$. For the endpoint of overlapping,
to make the length of the overlapping as large as possible, the endpoint point
to be as large as possible, so we would like to consider the largest endpoint
of previous intervals $t$. If $t \geq b_i$, then the overlapping is $[a_i, b_i]$.
If $t < b_i$, the overlapping is $[a_i, t]$. A special case is $t < a_i$, where
no overlapping is found, and the length is 0. Therefore, the maximum 
overlapping with previous intervals is $\max(\min(t, b_i) - a_i, 0)$.

Given this claim, we know that for each iteration we calculate the maximum
overlapping of current interval with previous intervals, and compare current 
maximum overlapping $curr\_d$ with maximum overlapping length of previous
intervals $d$,
and update the maximum appropriately $d = \max(d, curr\_d)$. Therefore, we can
conclude that $d$ is the maximum length of overlapping.

\subsection*{Time complexity}
The algorithm first sort all intervals in ascending order of starting point,
which has a time complexity of $O(n\log n)$. To calculate the maximum
overlapping, the algorithm scans from left to right, and the time for each
iteration is constant. Therefore, the time complexity for this step is $O(n)$.
Therefore, the time complexity of the algorithm is $O(n\log n)$.

\section{132 pattern}
\subsection*{Algorithm description:}
Let $A[1...n]$ be the input array,
\begin{enumerate}
\item Scan from left to right, and use $B$ to track the current minimum element,
that is, the minimum of the elements in the subarray that has been scanned thus 
far (excluding currently scanned element).

\item Scan from right to left, and use $C$ to track the predecessor of current
element, that is, the maximum element that is smaller than current element in
the subarray that has been scanned thus far. If no predecessor is found, $C[i]$
is set to $+\infty$. If $2 \leq i \leq n-1$ and $B[i] < C[i] < A[i]$, then we have found a
$132$-pattern, return true. 

\end{enumerate}
If no $132$-pattern is found after the second scan, return false.

\subsection*{Pseudocode}
\begin{minted}[frame=lines, framesep=2mm]{cpp}
  Input: A[1...n]
  Output: patternExists
  
  patternExists = false;
  min = +INF;
  B = [];
  for (int i = 1; i <= n; i++) {
    B[i] = min;
    if (A[i] < min) {
      min = A[i];
    }
  }
  
  bst = createBalancedBST(); // Create balanced binary search tree.
  for (int i = n; i >= 2; i--) {
    if (i > 1 && i < n) {
      pred = bst.findPredecessor(A[i]); // Find predecessor of A[i].
      if (B[i] < pred && pred < A[i]) {
        patternExists = true;
        break;
      }
    }
    bst.insert(A[i]);
  }
  return patternExists;
\end{minted}

\subsection*{Proof of correctness}
\begin{claim}
  We can find a $132$-pattern with $a_j$ as the largest element if and only if
  $B[j] < C[j] < a_j$, where $B[i]$ is the minimum element in the subarray
  $a[1\dots j-1]$, and $C(j)$ is the predecessor of $a_j$ in the subarray
  $a[j+1\dots n]$.
\end{claim}

\textbf{Proof:}
If $B[j] < C[j] < a_j$, obviously $B[j], C[j], a_j$ is a $132$-pattern.

If there is a $132$-pattern in the subarray with $a_j$ as the largest element,
then there exists $i < j < k$ such that $a_i < a_k < a_j$. $C[j]$ is the 
predecessor of $a_j$ in the right subarray, so $a_k \leq C[j] < a_j$.
$B[j]$ is the minimum element in the left subarray, so $B[j] \leq a_i$.
So we have $B[j] < C[j] < a_j$.

Therefore the claim holds.
\vspace{0.5cm}

Given this claim, we know that there exists a $132$-pattern in the array
if and only if there exists $2 \leq j \leq n-1$ satisfying $B[j] < C[j] < a_j$.
Therefore, the algorithm do a first scan from left to right to find the minimum 
element in the left subarray of each element. And then do a second scan from 
right to left to find the predecessor of each element in the right subarray, and
compare the value of predecessor, the minimum element in the left subarray and
current element. If it satisfies $B[j] < C[j] < a_j$, then there exists a 
$132$-pattern in the array. If no $132$-pattern is found after the second scan,
then there is no $132$-pattern in the array.

\subsection*{Time complexity}
The time complexity for finding minimum element in the left subarray is $O(n)$.
To find a predecessor of an element, we build a balanced binary search tree,
and when we scan from right to left, we insert the element in the tree, which is 
an $O(\log n)$ operation, and finding the predecessor of an element in balanced
binary search tree is also $O(\log n)$. The time complexity for
second scan is $O(n\log n)$. Therefore, the time complexity of the algorithm is
$(n\log n)$.

\section{Toeplitz matrices}
\subsection*{1}
The sum of two Toeplitz matrices is also Toeplitz.

\textbf{Proof:}
Let $A = (a_{ij}), B = (b_{ij})$ be two Toeplitz matrices, $C = A + B$, then
\begin{align}
  \begin{split}
    c_{i,j} &= a_{i,j} + b_{i,j} \\
           &= a_{i-1,j-1} + b_{i-1,j-1} \\
           &= c_{i-1,j-1} 
  \end{split}
\end{align}
Therefore $C$ is also Toeplitz.

The product of two Toeplitz matrices is not necessarily Toeplitz. A
counter-example is as following:
\begin{align}
  \begin{split}
    A &= \begin{bmatrix}
      1 & 0 \\
      1 & 1 
    \end{bmatrix} \\
    B &= \begin{bmatrix}
      2 & 1 \\
      0 & 2 
    \end{bmatrix} \\
    C &= AB = \begin{bmatrix}
      2 & 1 \\
      2 & 3 
    \end{bmatrix}
  \end{split}
\end{align}
Obviously $C$ is not Toeplitz.

\subsection*{2}
We could use the first row and first column of the matrix to represent a
Toeplitz matrix. That is,
\begin{equation}
  A \overset{\Delta}{=} [A_{1, 1...n}; A_{1...n, 1}], \text{where $A$ is a
  Toeplitz matrix}
\end{equation}
In this way, $A$ can be reconstructed as following:
\[
\begin{bmatrix}
  A_{1,1} & A_{1, 2} & \dots & A_{1, n} \\
  A_{2,1} & A_{1, 1} & \dots & A_{1, n-1} \\
  \vdots & \vdots  & \ddots & \vdots \\
  A_{n,1} & A_{n-1, 1} & \dots & A_{1,1}
\end{bmatrix}
\]
Therefore we just need to add $2n$ elements when adding two Toeplitz
matrices, and the complexity is $O(n)$.

\subsection*{3}
First we construct another Toeplitz matrix $B$ and $C$ as following:
\begin{align}
  \begin{split}
    B &= [0, A_{n, 1}, A_{n-1, 1}, \dots, A_{2, 1}; 0, A_{1, n}, A_{1, n-1},
    \dots, A_{1, 2}] \\
    C &= \begin{bmatrix}
      A & B \\
      B & A \\
    \end{bmatrix}
  \end{split}
\end{align}

Then we know that $C$ is a \textit{circulant matrix}, which has the property
that it can be diagonalized by the DFT matrix, that is $C = F^{-1}\Lambda F$,
where $F$ is the DFT matrix.

To calculate the product of $A$ and vector $v$, we have 
\begin{align}
  \begin{split}
    Av & = (\mathbf{I}_{n\times n} \mathbf{0}_{n\times n}) C \begin{bmatrix}
      v \\
      \mathbf{0}_{n \times 1}
    \end{bmatrix} \\
    &= (\mathbf{I}_{n\times n} \mathbf{0}_{n\times n}) F^{-1}\Lambda F\begin{bmatrix}
      v \\
      \mathbf{0}_{n \times 1}
    \end{bmatrix} 
  \end{split}
  \label{equ:5-3}
\end{align}

We also know that the product of DFT matrix as well as inverse DFT matrix with a vector can be calculated in 
$O(n\log n)$. Therefore for Equation~\ref{equ:5-3}, the time complexity is
analyzed as following:
\begin{enumerate}
  \item $F *: O(n\log n)$
  \item $\Lambda *: O(n) $
  \item $F^{-1} *: O(n\log n) $
  \item $(\mathbf{I}_{n\times n} \mathbf{0}_{n\times n}) * : O(n) $
\end{enumerate}
Thus the time complexity is $O(n\log n)$.

\subsection*{4}
The product of two Toeplitz matrices can be calculated in $O(n^2)$ time.

Let $A$ and $B$ be two $n\times n$ Toeplitz matrices, and $T = AB$. 
\begin{enumerate}
  \item We calculate the first row and first column of $T$. To calculate the
    first column, we multiply $A$ by first column of $B$, which is $O(n\log n)$.
    To calculate the first row, we multiply the first row of $A$ by $B$, which
    is also $O(n\log n)$.
  \item For remaining entries $T_{i,j}$ in $T$, each of them can be calculated in constant 
    time from $T_{i-1, j-1}$. The proof is as following:
      \begin{align}
        \begin{split}
          T_{i-1, j-1} &= \sum_{k=1}^{n} A_{i-1, k} B_{k,j-1} \\
          T_{i, j} &= \sum_{k=1}^{n} A_{i, k} B_{k, j} \\
                &= A_{i,1}B_{1,j} + \sum_{k=2}^{n} A_{i, k} B_{k, j} \\
                &= A_{i,1}B_{1,j} + \sum_{k=2}^n A_{i-1, k-1} B_{k-1, j-1} \\
                &= A_{i,1}B_{1,j} + \sum_{k=1}^n A_{i-1, k} B_{k-1, k} -
                A_{i-1, n}B_{n,j} \\
                &= T_{i-1, j-1} + A_{i,1}B_{1,j} - A_{i-1, n}B_{n,j} \\
        \end{split}
      \end{align}
    Therefore, $T_{i, j}$ can be calculated in constant time from $T_{i-1,j-1}$.
    Given this, we know that all remaining entries can be calculated in $O(n^2)$
    time.
\end{enumerate}
That is, the time complexity of the proposed algorithm for multiplying two
Toeplitz matrices is $O(n^2)$.
\end{document}
